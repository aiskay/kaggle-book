{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 6.3 クラスの分布が偏っている場合\n",
    "\n",
    "分類ラベルの分布が偏っている場合の対処法\n",
    "\n",
    "## アンダーサンプリング\n",
    "\n",
    "例えば異常検知など正例が異常に少ない場合、負例の一部のみを使用してモデルを学習させる方法。  \n",
    "また、異なる負例を取り出して学習させた複数のモデルを平均する手法 (バギング) も有効。\n",
    "\n",
    "kaggle の [TalkingData AdTracking Fraud Detection Challenge](https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection) というコンペでは、1 億件以上のデータのうち正例は 0.2 % 程度であり、\n",
    "1 位の解法はほとんどの負例を捨てて精度を出していた。\n",
    "\n",
    "## 特に工夫をしない\n",
    "\n",
    "特に工夫をしなくても十分な精度が出ることも多い。\n",
    "\n",
    "## 重み付け\n",
    "\n",
    "parameter 更新の際の正例と負例の寄与の合計が等しくなるように正例に高い weight を指定する方法。\n",
    "\n",
    "## オーバーサンプリング\n",
    "\n",
    "負例の方が多い場合に、正例を増やして学習をさせる方法。  \n",
    "Synthetic Minority Oversampling Technique (SMOTE) といった手法がある。\n",
    "\n",
    "## 確率を予測する必要がある場合の注意点\n",
    "\n",
    "評価指標が logloss などで適切な確率を予測する必要がある場合、正例と負例の比率を変えた場合は確率の補正を忘れずに行うように。  \n",
    "(2.5.4 確率の予測値とその調整 を参照)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}