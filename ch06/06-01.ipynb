{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 6.1 パラメータチューニング\n",
    "\n",
    "## 6.1.1 ハイパーパラメータの探索手法\n",
    "\n",
    "1. 手動\n",
    "2. グリッドサーチ/ランダムサーチ  \n",
    "   パラメータ空間を予め指定した範囲を規則的に探索/予め指定した手法でランダムに探索  \n",
    "   `sckikit-learn.model_selection` の `GridSearchCV`, `RandomizedSearchCV` など\n",
    "3. ベイズ最適化 (Bayseian Optimization)  \n",
    "    以前に計算したパラメータの履歴に基づいてベイズの手法を用いて選択  \n",
    "    `hyperopt`, `optuna` など\n",
    "\n",
    "kaggle でのパラメータ探索は手で行っている人が多い印象。\n",
    "\n",
    "## 6.1.2 パラメータチューニングで設定すること\n",
    "\n",
    "1. ベースラインとなるパラメータ\n",
    "2. 探索する対象となるパラメータとその範囲\n",
    "3. 手動で調節するか、自動的に探索するか\n",
    "4. 評価の枠組み (fold の分け方など)\n",
    "\n",
    "パラメータを自動で調節する場合には、\n",
    "\n",
    "- パラメータチューニングをしすぎて学習データに過剰に適合してしまう\n",
    "- 計算時間が長くなる\n",
    "\n",
    "といった問題が起こり得るので、\n",
    "\n",
    "- チューニングとモデルの作成をする際の fold の分け方を変える\n",
    "- validation の fold の 1 つだけを用いて精度を確認する\n",
    "\n",
    "などの対策をしたほうが良い。\n",
    "\n",
    "## 6.1.3 パラメータチューニングのポイント\n",
    "\n",
    "各モデルには結果を大きく左右する大事なパラメータが存在する。  \n",
    "そのため、パラメータを探索する際はその**モデルの重要なパラメータから調節していく**ことが大事である。  \n",
    "\n",
    "また、**モデルとパラメータの関係を理解して得られた結果からなぜそうなったのかを理解すること**で、次にどうパラメータを変化させるべきかを考えながらチューニングしていくとよい。\n",
    "\n",
    "なお、GBDT ではパラメータチューニングよりも良い特徴量を追加するほうが有用なことが多いので、あまりチューニングに時間を割かない方が良い。\n",
    "\n",
    "\n",
    "## 6.1.4 ベイズ最適化でのパラメータ探索\n",
    "\n",
    "Tree-structured Parzen Estimator (TPE) というアルゴリズムを用いて最適化を行っている `hyperopt` と `optuna` について、以下具体的な使い方を見ていく。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# ---------------------------------\n",
    "# データ等の準備\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "\n",
    "train = pd.read_csv('../input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]  # 最初の fold のみ用いる\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "# xgboostによる学習・予測を行うクラス\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'verbosity': 1, 'random_state': 71}\n",
    "        params.update(self.params)\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.model = xgb.train(params, dtrain, num_round, verbose_eval=False, evals=watchlist)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [`hyperopt`](http://hyperopt.github.io/hyperopt/)\n",
    "\n",
    "具体的な手順は以下のよう。\n",
    "\n",
    "1. 最小化したい評価指標を返す関数を作成する (`score` function) \n",
    "2. 探索するパラメータ範囲を定義する (`space` 変数)\n",
    "3. 探索回数を指定する (`max_eval` 変数)\n",
    "\n",
    "以上を `hyperopt.fmin` 関数に代入して探索を行う。\n",
    "\n",
    "経験的には 25 回程度の探索でそれなりに妥当なパラメータが見つかり始め、100 回程度で十分な探索が行われるようである。\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# -----------------------------------\n",
    "# hyperoptを使ったパラメータ探索\n",
    "# -----------------------------------\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    # パラメータを与えたときに最小化する評価指標を指定する\n",
    "    # 具体的には、モデルにパラメータを指定して学習・予測させた場合のスコアを返すようにする\n",
    "\n",
    "    # max_depthの型を整数型に修正する\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "    # Modelクラスを定義しているものとする\n",
    "    # Modelクラスは、fitで学習し、predictで予測値の確率を出力する\n",
    "    model = Model(params)\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    print(f'params: {params}, logloss: {score:.4f}')\n",
    "\n",
    "    # 情報を記録しておく\n",
    "    history.append((params, score))\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# 探索するパラメータの空間を指定する\n",
    "# hp.choiceでは、複数の選択肢から選ぶ\n",
    "# hp.uniformでは、下限・上限を指定した一様分布から抽出する。引数は下限・上限\n",
    "# hp.quniformでは、下限・上限を指定した一様分布のうち一定の間隔ごとの点から抽出する。引数は下限・上限・間隔\n",
    "# hp.loguniformでは、下限・上限を指定した対数が一様分布に従う分布から抽出する。引数は下限・上限の対数をとった値\n",
    "space = {\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 5, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 9, 1),\n",
    "    'gamma': hp.quniform('gamma', 0, 0.4, 0.1),\n",
    "}\n",
    "\n",
    "# hyperoptによるパラメータ探索の実行\n",
    "max_evals = 20\n",
    "trials = Trials()\n",
    "history = []\n",
    "fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=max_evals)\n",
    "\n",
    "# 記録した情報からパラメータとスコアを出力する\n",
    "# （trialsからも情報が取得できるが、パラメータの取得がやや行いづらいため）\n",
    "history = sorted(history, key=lambda tpl: tpl[1])\n",
    "best = history[0]\n",
    "print(f'best params:{best[0]}, score:{best[1]:.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'gamma': 0.30000000000000004, 'max_depth': 4, 'min_child_weight': 2.0}, logloss: 0.3221\n",
      "params: {'gamma': 0.1, 'max_depth': 8, 'min_child_weight': 2.0}, logloss: 0.2851\n",
      "params: {'gamma': 0.1, 'max_depth': 4, 'min_child_weight': 4.0}, logloss: 0.3267\n",
      "params: {'gamma': 0.1, 'max_depth': 7, 'min_child_weight': 2.0}, logloss: 0.2880\n",
      "params: {'gamma': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 2.0}, logloss: 0.2849\n",
      "params: {'gamma': 0.2, 'max_depth': 5, 'min_child_weight': 4.0}, logloss: 0.3147\n",
      "params: {'gamma': 0.2, 'max_depth': 9, 'min_child_weight': 2.0}, logloss: 0.2792\n",
      "params: {'gamma': 0.30000000000000004, 'max_depth': 4, 'min_child_weight': 4.0}, logloss: 0.3267\n",
      "params: {'gamma': 0.1, 'max_depth': 7, 'min_child_weight': 4.0}, logloss: 0.2942\n",
      "params: {'gamma': 0.30000000000000004, 'max_depth': 3, 'min_child_weight': 4.0}, logloss: 0.3543\n",
      "params: {'gamma': 0.30000000000000004, 'max_depth': 7, 'min_child_weight': 4.0}, logloss: 0.2940\n",
      "params: {'gamma': 0.2, 'max_depth': 4, 'min_child_weight': 5.0}, logloss: 0.3229\n",
      "params: {'gamma': 0.4, 'max_depth': 8, 'min_child_weight': 2.0}, logloss: 0.2923\n",
      "params: {'gamma': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 1.0}, logloss: 0.3077\n",
      "params: {'gamma': 0.0, 'max_depth': 5, 'min_child_weight': 3.0}, logloss: 0.3058\n",
      "params: {'gamma': 0.4, 'max_depth': 3, 'min_child_weight': 3.0}, logloss: 0.3543\n",
      "params: {'gamma': 0.1, 'max_depth': 6, 'min_child_weight': 4.0}, logloss: 0.3037\n",
      "params: {'gamma': 0.2, 'max_depth': 5, 'min_child_weight': 4.0}, logloss: 0.3147\n",
      "params: {'gamma': 0.0, 'max_depth': 4, 'min_child_weight': 2.0}, logloss: 0.3219\n",
      "params: {'gamma': 0.2, 'max_depth': 3, 'min_child_weight': 5.0}, logloss: 0.3543\n",
      "100%|██████████| 20/20 [00:02<00:00,  9.64trial/s, best loss: 0.27921653158441184]\n",
      "best params:{'gamma': 0.2, 'max_depth': 9, 'min_child_weight': 2.0}, score:0.2792\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `optuna`\n",
    "\n",
    "2018 年末に公開されたフレームワークで、最適化のアルゴリズムに TPE を用いているのは hyperopt と同じだが、\n",
    "API が使いやすく、そしてより効率的になっている[<sup>1</sup>](#fn1)。\n",
    "\n",
    "個人的には最近よく聞くのはこっちな気がする。\n",
    "\n",
    "<span id=\"fn1\"> https://optuna.readthedocs.io/en/stable/ </span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0, 0.4),\n",
    "    }\n",
    "    model = Model(params)\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "\n",
    "    print(f'params: {params}, logloss: {score:.4f}')\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f'best params:{study.best_params}, score:{study.best_value:.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:06,451]\u001b[0m A new study created in memory with name: no-name-f643c0b5-0daf-479b-b6a0-ebf0bc35e1f7\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:06,543]\u001b[0m Trial 0 finished with value: 0.3147349045306444 and parameters: {'min_child_weight': 4, 'max_depth': 5, 'gamma': 0.13116261102965884}. Best is trial 0 with value: 0.3147349045306444.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:06,594]\u001b[0m Trial 1 finished with value: 0.3542746682226658 and parameters: {'min_child_weight': 1, 'max_depth': 3, 'gamma': 0.3284449296487035}. Best is trial 0 with value: 0.3147349045306444.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:06,692]\u001b[0m Trial 2 finished with value: 0.30089185103923083 and parameters: {'min_child_weight': 1, 'max_depth': 6, 'gamma': 0.04387353487753463}. Best is trial 2 with value: 0.30089185103923083.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 4, 'max_depth': 5, 'gamma': 0.13116261102965884}, logloss: 0.3147\n",
      "params: {'min_child_weight': 1, 'max_depth': 3, 'gamma': 0.3284449296487035}, logloss: 0.3543\n",
      "params: {'min_child_weight': 1, 'max_depth': 6, 'gamma': 0.04387353487753463}, logloss: 0.3009\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:06,851]\u001b[0m Trial 3 finished with value: 0.28736135601624846 and parameters: {'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.04928800677802361}. Best is trial 3 with value: 0.28736135601624846.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:06,961]\u001b[0m Trial 4 finished with value: 0.291297506006062 and parameters: {'min_child_weight': 3, 'max_depth': 7, 'gamma': 0.04807251312640477}. Best is trial 3 with value: 0.28736135601624846.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.04928800677802361}, logloss: 0.2874\n",
      "params: {'min_child_weight': 3, 'max_depth': 7, 'gamma': 0.04807251312640477}, logloss: 0.2913\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:07,099]\u001b[0m Trial 5 finished with value: 0.28764107541665435 and parameters: {'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.22122485704736428}. Best is trial 3 with value: 0.28736135601624846.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:07,161]\u001b[0m Trial 6 finished with value: 0.3228588599473238 and parameters: {'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.18875010745446677}. Best is trial 3 with value: 0.28736135601624846.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:07,210]\u001b[0m Trial 7 finished with value: 0.3542746682226658 and parameters: {'min_child_weight': 2, 'max_depth': 3, 'gamma': 0.20096694125766287}. Best is trial 3 with value: 0.28736135601624846.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.22122485704736428}, logloss: 0.2876\n",
      "params: {'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.18875010745446677}, logloss: 0.3229\n",
      "params: {'min_child_weight': 2, 'max_depth': 3, 'gamma': 0.20096694125766287}, logloss: 0.3543\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:07,332]\u001b[0m Trial 8 finished with value: 0.2856548336714506 and parameters: {'min_child_weight': 3, 'max_depth': 7, 'gamma': 0.39154536156840475}. Best is trial 8 with value: 0.2856548336714506.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:07,484]\u001b[0m Trial 9 finished with value: 0.3266707164883614 and parameters: {'min_child_weight': 4, 'max_depth': 4, 'gamma': 0.34160306699107124}. Best is trial 8 with value: 0.2856548336714506.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 3, 'max_depth': 7, 'gamma': 0.39154536156840475}, logloss: 0.2857\n",
      "params: {'min_child_weight': 4, 'max_depth': 4, 'gamma': 0.34160306699107124}, logloss: 0.3267\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:07,657]\u001b[0m Trial 10 finished with value: 0.2808158458508551 and parameters: {'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.37614066977996474}. Best is trial 10 with value: 0.2808158458508551.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.37614066977996474}, logloss: 0.2808\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:07,867]\u001b[0m Trial 11 finished with value: 0.283472646099329 and parameters: {'min_child_weight': 3, 'max_depth': 8, 'gamma': 0.3910393642499814}. Best is trial 10 with value: 0.2808158458508551.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:08,025]\u001b[0m Trial 12 finished with value: 0.28535056088268757 and parameters: {'min_child_weight': 4, 'max_depth': 9, 'gamma': 0.3004968484301267}. Best is trial 10 with value: 0.2808158458508551.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 3, 'max_depth': 8, 'gamma': 0.3910393642499814}, logloss: 0.2835\n",
      "params: {'min_child_weight': 4, 'max_depth': 9, 'gamma': 0.3004968484301267}, logloss: 0.2854\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:08,183]\u001b[0m Trial 13 finished with value: 0.28083665127381685 and parameters: {'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.39200669216508943}. Best is trial 10 with value: 0.2808158458508551.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:08,317]\u001b[0m Trial 14 finished with value: 0.28455618872717026 and parameters: {'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.2630643414003324}. Best is trial 10 with value: 0.2808158458508551.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.39200669216508943}, logloss: 0.2808\n",
      "params: {'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.2630643414003324}, logloss: 0.2846\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:08,518]\u001b[0m Trial 15 finished with value: 0.28092730995714665 and parameters: {'min_child_weight': 2, 'max_depth': 9, 'gamma': 0.3995490529163783}. Best is trial 10 with value: 0.2808158458508551.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:08,638]\u001b[0m Trial 16 finished with value: 0.2940039627045393 and parameters: {'min_child_weight': 4, 'max_depth': 7, 'gamma': 0.2800725105935713}. Best is trial 10 with value: 0.2808158458508551.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 2, 'max_depth': 9, 'gamma': 0.3995490529163783}, logloss: 0.2809\n",
      "params: {'min_child_weight': 4, 'max_depth': 7, 'gamma': 0.2800725105935713}, logloss: 0.2940\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:08,816]\u001b[0m Trial 17 finished with value: 0.2805261413246393 and parameters: {'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.34452935506123883}. Best is trial 17 with value: 0.2805261413246393.\u001b[0m\n",
      "\u001b[32m[I 2021-10-03 09:40:08,918]\u001b[0m Trial 18 finished with value: 0.3012499739944935 and parameters: {'min_child_weight': 3, 'max_depth': 6, 'gamma': 0.3451364003050326}. Best is trial 17 with value: 0.2805261413246393.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.34452935506123883}, logloss: 0.2805\n",
      "params: {'min_child_weight': 3, 'max_depth': 6, 'gamma': 0.3451364003050326}, logloss: 0.3012\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-03 09:40:09,069]\u001b[0m Trial 19 finished with value: 0.28517025641947985 and parameters: {'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.12198721505975081}. Best is trial 17 with value: 0.2805261413246393.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "params: {'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.12198721505975081}, logloss: 0.2852\n",
      "best params:{'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.34452935506123883}, score:0.2805\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ただ、ベイズ最適化によるチューニングでは以下のような問題が生じることがある。\n",
    "\n",
    "- 計算時間のかかりすぎる試行  \n",
    "  学習率を小さくした場合は学習がなかなか進まなくなってしまうので、事前に調整しておくなどの対策が必要。\n",
    "- パラメータ間の依存性\n",
    "  チューニングされるパラメータ同士は完全に独立でないため、依存性が強く表れる場合は効率的な探索ができない可能性がある。  \n",
    "  パラメータ空間を明示的にするか、試行回数を増やす必要がある。\n",
    "- 評価のランダム性によるばらつき\n",
    "  評価のぶれが大きいときは効果的に探索できないので、cross validation の平均で評価するなど試行回数を増やすなどの必要がある。\n",
    "\n",
    "従って、ベイズ最適化を使う場合はこれらの点に注意すること。\n",
    "\n",
    "## 5.1.5 GBDT のパラメータおよびそのチューニング\n",
    "\n",
    "xgboost のパラメータ\n",
    "\n",
    "<center>\n",
    "|      parameter     | explanation |\n",
    "|:------------------:|:-----------:|\n",
    "|        `eta`       | 学習率      |\n",
    "|     `num_round`    |             |\n",
    "|     `max_depth`    |             |\n",
    "| `min_child_weight` |             |\n",
    "|       `gamma`      |             |\n",
    "| `colsample_bytree` |             |\n",
    "|     `subsample`    |             |\n",
    "|       `alpha`      |             |\n",
    "|      `lambda`      |             |\n",
    "\n",
    "<\\center>\n",
    "\n",
    "具体的なチューニングの例は p.321 - の COLUMN を参考に。\n",
    "\n",
    "## 5.1.6 ニューラルネットのパラメータおよびそのチューニング\n",
    "\n",
    "\n",
    "\n",
    "具体的なチューニングの例は p.321 - の COLUMN を参考に。\n",
    "\n",
    "\n",
    "## 5.1.7 線形モデルのパラメータおよびそのチューニング\n",
    "\n",
    "線形モデルでは正則化のパラメータがチューニング対象となる。  \n",
    "対象のパラメータが少なく計算も比較的早いので、広範囲を探索することが可能である。\n",
    "\n",
    "Ref. [正則化（Ridge,Lasso）](https://qiita.com/greatonbi/items/0322d420af46d3ed9183)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}